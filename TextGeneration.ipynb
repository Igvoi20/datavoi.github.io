{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled36.ipynb",
      "provenance": [],
      "mount_file_id": "157f49JmF5wHbtvZheNWTTRS4b7yTqhwR",
      "authorship_tag": "ABX9TyM0uJakSomnLTZIVkgZ1x1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igorvojnyak/datavojnyak.github.io/blob/master/TextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqN7mBJxR1Ne",
        "outputId": "e11de1c8-f7a5-4580-ba7b-6ed6746e32a3"
      },
      "source": [
        "!pip install pyyaml h5py  # –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ HDF5"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7lTOTzHosRh",
        "outputId": "55de4d12-ea85-47ad-f55b-11a21b2a361c"
      },
      "source": [
        "pip install meduza\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting meduza\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/8c/74fbd754c670810641a47be828019ba32f1b9649720db5f479dac90c0e23/meduza-20.7.2.tar.gz\n",
            "Building wheels for collected packages: meduza\n",
            "  Building wheel for meduza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for meduza: filename=meduza-20.7.2-cp36-none-any.whl size=4599 sha256=69713e8e9ab99f6b28fedec391c50e938b091b288ad70b089af81cacb38c816d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/b6/0e/885bd0b8bfbcf2d1fabe0c19372d99f52a37d2f062bf2e2a22\n",
            "Successfully built meduza\n",
            "Installing collected packages: meduza\n",
            "Successfully installed meduza-20.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alTFouZ2otma",
        "outputId": "a5086ba2-84d8-4133-c905-a9516047a1af"
      },
      "source": [
        "pip install newsapi-python"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newsapi-python\n",
            "  Downloading https://files.pythonhosted.org/packages/de/9e/9050199ac7cbc755d1c49577fdaa5517901124b574264b3602a8b8028440/newsapi_python-0.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from newsapi-python) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (1.24.3)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ta_ANWdbxBa",
        "outputId": "7c6db3b5-1618-4dc7-9a02-69a8243c33d9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import logging\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.externals import joblib\n",
        "import gensim\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import json\n",
        "import numpy\n",
        "import sys\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import requests\n",
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize \n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import meduza\n",
        "from string import punctuation\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from string import punctuation"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epif9LeIbkbN"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "# load ascii text and covert to lowercase\n",
        "# filename = \"/content/d.txt\"\n",
        "# raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "# raw_text = raw_text.lower()\n",
        "# text =re.sub(r\"[#%¬´!@¬ª‚ÄîA-Za-z*]\", \"\", raw_text) \n",
        "# raw_text = raw_text.translate(str.maketrans(\"\", \"\", punctuation))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-yhkLK7o0v6"
      },
      "source": [
        "def remove_html_tags(text):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    import re\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTlwVsTAo71j"
      },
      "source": [
        "import requests\n",
        "url = ('https://newsapi.org/v2/everything?q=–Ω–æ–≤–æ—Å—Ç–∏&apiKey=49966f3d107f48ce904d1d8dda75ddbd')\n",
        "response = requests.get(url)\n",
        "json_data = response.json()\n",
        "data = pd.DataFrame(columns=['titles'])\n",
        "result = []\n",
        "for title in json_data[\"articles\"]:\n",
        "    result.append(title['title'])\n",
        "    #print(title['title'])\n",
        "    result.append(title['description'])\n",
        "    # for extr_title in title['title']:\n",
        "    #     #result.extend(extr_title)\n",
        "    #     print('efe')\n",
        "\n",
        "        #df['titles'] = result\n",
        "        #file_object = open('/content/data.txt', 'a')\n",
        "        #file_object.write(\" \")\n",
        "        #file_object.write(remove_html_tags(extr_title))\n",
        "    # for extr_description in title['description']: \n",
        "    #     result.append(extr_description)\n",
        "        #file_object = open('/content/data.txt', 'a')\n",
        "        #file_object.write(\" \")\n",
        "        #file_object.write(remove_html_tags (extr_description))\n",
        "\n",
        "        \n",
        "\n",
        "#file_object.close()\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z_WEPZ-o05q"
      },
      "source": [
        "def get_titles(url):\n",
        "    r = requests.get(url)\n",
        "    html = BeautifulSoup(r.content, 'html.parser')\n",
        "    table = html.find_all(\"title\")\n",
        "    description = html.find_all(\"description\")\n",
        "    for title in table:\n",
        "        #df['titles']= title.text\n",
        "        result.append(title.text)\n",
        "        #file_object = open('/content/data.txt', 'a')\n",
        "        #file_object.write(title.text)\n",
        "        #file_object.write(\" \")\n",
        "    for descr in description:\n",
        "        #df['titles']= descr.text\n",
        "        result.append(descr.text)\n",
        "        #file_object = open('/content/data.txt', 'a')\n",
        "        #file_object.write(descr.text)\n",
        "        #file_object.write(\" \")\n",
        "    \n",
        "    #file_object.close()"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZAATMqco0_E"
      },
      "source": [
        "get_titles('https://lenta.ru/rss/articles')\n",
        "get_titles('https://news.yandex.ru/politics.rss')\n",
        "get_titles('https://meduza.io/rss2/all')\n",
        "get_titles('https://www.liga.net/news/all/rss.xml')\n",
        "get_titles('https://rg.ru/tema/gos/rss.xml')\n",
        "get_titles('https://rg.ru/xml/index.xml')\n",
        "get_titles('http://k.img.com.ua/rss/ru/russia.xml')\n",
        "get_titles('http://k.img.com.ua/rss/ru/all_news2.0.xml')\n",
        "get_titles('https://rss.newsru.com/world')\n",
        "get_titles('https://gordonua.com/xml/rss.html')\n",
        "get_titles('https://www.sostav.ru/rss')\n",
        "get_titles('https://news.mail.ru/rss/economics/')\n",
        "get_titles('https://www.vesti.ru/vesti.rss')\n",
        "get_titles('https://news.mail.ru/rss/society/')\n",
        "get_titles('https://news.yandex.ru/world.rss')\n",
        "get_titles('https://news.mail.ru/rss/politics/')\n",
        "get_titles('https://news.mail.ru/rss/')\n",
        "get_titles('https://news.mail.ru/rss/main/')\n",
        "get_titles('https://news.rambler.ru/rss/world/')\n",
        "get_titles('https://news.rambler.ru/rss/articles/')\n",
        "get_titles('https://news.rambler.ru/rss/Moscow/')\n",
        "get_titles('https://news.rambler.ru/rss/moscow_city/')\n",
        "get_titles('https://ria.ru/export/rss2/archive/index.xml')\n",
        "get_titles('https://lenta.ru/rss/articles')\n",
        "get_titles('https://lenta.ru/rss/news/russia')\n",
        "get_titles('https://lenta.ru/rss/last24')\n",
        "get_titles('https://lenta.ru/rss/top7')\n",
        "get_titles('https://lenta.ru/rss/articles/russia')\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EURW1O3wo0y8"
      },
      "source": [
        "from newsapi import NewsApiClient\n",
        "newsapi = NewsApiClient(api_key='49966f3d107f48ce904d1d8dda75ddbd')\n",
        "all_articles = newsapi.get_everything(q='–Ω–æ–≤–æ—Å—Ç–∏',\n",
        "                                      language='ru',\n",
        "                                      sort_by='relevancy',\n",
        "                                      page=5)\n",
        "for title in all_articles[\"articles\"]:\n",
        "    #print(title['title'])\n",
        "    titles = remove_html_tags(title['description'])\n",
        "    result.append(titles)\n",
        "    #print(titles)\n",
        "    #for extr_title in titles:\n",
        "        #file_object = open('/content/data.txt', 'a')\n",
        "        #file_object.write(extr_title)\n",
        "        #file_object.write(\" \")\n",
        "\n",
        "    #file_object.close()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gu3f3Y-rALH"
      },
      "source": [
        "url = \"https://meduza.io/en/brief/2020/11/07/the-real-russia-today\"\n",
        "article = meduza.get(url)\n",
        "#data = []\n",
        "for article in meduza.section('news', n=1000, lang='ru'):\n",
        "    #print(article['title'])\n",
        "    result.append(article['title'])\n",
        "    #data.append(f\" '{article['title']}'\")\n",
        "    #file_object = open('/content/data.txt', 'a')\n",
        "    #file_object.write(f\" '{article['title']}'\")\n",
        "    \n",
        "\n",
        "# Close the file\n",
        "#file_object.close()"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMzBCrvQ1R1y"
      },
      "source": [
        "data = pd.DataFrame(columns=['text'])"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKWDoH3QrAId"
      },
      "source": [
        "data['text'] = result"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "DHoIreomb153",
        "outputId": "760016f8-f446-4701-81ab-157781af3908"
      },
      "source": [
        "#import the data\n",
        "#data_path = 'C:/Users/Downloads/.....csv'\n",
        "#data = pd.read_csv(data_path)\n",
        "\n",
        "#Function to clean the text\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    #text = text.replace('\\%','')\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text =re.sub(r\"[xxx:\\r\\n\\n¬£'‚Üí‚ù§üé©üòé#‚Ññ\\u200e\\u202f\\xa0¬´¬ª%¬´!@¬ª‚ÄîA-Za-z*]\", \"\", text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text =re.sub(\"\\xa0¬£\", \"\", text) \n",
        "    text = re.sub('[%s]' % re.escape(punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    bad_chars = ['+',';', ':', '!', \"*\",\"\\xa0\"]\n",
        "    for i in bad_chars :\n",
        "        text = text.replace(i, '')\n",
        "    data = text.translate(str.maketrans(\"\", \"\", punctuation))\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = \" \".join(filter(lambda x:x[0]!=\"@\", text.split()))\n",
        "    return text\n",
        "\n",
        "#Apply the function\n",
        "data['text'] = data['text'].apply(lambda x: clean_text(x))\n",
        "data = data['text']"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-174-03f9f60359ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#Apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0bfsrjM2Nwp",
        "outputId": "76266655-b1eb-4350-c832-6078108f02a8"
      },
      "source": [
        "data.head(50)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ–ª–µ–Ω–Ω–æ–π\n",
              "1     –æ–∫—Ç—è–±—Ä—è —Å–æ—Å—Ç–æ—è–ª–∞—Å—å –Ω–µ–±–æ–ª—å—à–∞—è –æ–Ω–ª–∞–π–Ω–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è...\n",
              "2                                        –Ω–æ–≤–æ—Å—Ç–∏ –≤—ã–ø—É—Å–∫\n",
              "3     –Ω–æ–≤–æ—Å—Ç–∏ –≤—ã–ø—É—Å–∫ –ø—Ä–∏–≤–µ—Ç —ç—Ç–æ –æ—á–µ—Ä–µ–¥–Ω–æ–π –≤—ã–ø—É—Å–∫ –Ω–æ–≤...\n",
              "4     –Ω–æ–≤–æ—Å—Ç–∏ —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤ –∏ –≤–µ–Ω—á—É—Ä–∞ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Ä–æ–∫–∏ –∑–∞ ...\n",
              "5     –ø—Ä–∏–≤–µ—Ç —Ö–∞–±—Ä —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é —è —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—é –æ –∫—Ä—É–ø–Ω...\n",
              "6                             —Ö–æ—Ä–æ—à–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ —Ç–æ–º—Å–∫–∞\n",
              "7     —Å–µ–≥–æ–¥–Ω—è —É—Ç—Ä–æ–º –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–∏–∫–∏ —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–º–∏—Ç...\n",
              "8                                            –Ω–æ–≤–æ—Å—Ç–∏ –∏—Ç\n",
              "9     –≤–∏–¥–µ–æ –Ω–∞ —é—Ç—É–±—Ç–µ–∫—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è–≤ –∫–∞–ø—Å—É–ª–µ –ø—Ä–æ–∫–∞—Ç–∏...\n",
              "10                                     –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏—Ç\n",
              "11    –≤–∏–¥–µ–æ –Ω–∞ —é—Ç—É–±—Ç–µ–∫—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è–æ—Å–µ–Ω—å—é –¥–ª—è –∞–π—Ç–∏—à–Ω...\n",
              "12                          –Ω–æ–≤–æ—Å—Ç–∏ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –ø–æ–ª–∏—Ç–∏–∫–∏\n",
              "13    –æ–ª—è –ø–æ–ª—è–∫–æ–≤–∞ –∏ –∫–∏—Ä–∫–æ—Ä–æ–≤ —Å–ø–µ–ª–∏ –≤–º–µ—Å—Ç–µ –≤ –¥—É–±–∞—è—Ö ...\n",
              "14                             –Ω–µ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∏–µ –Ω–æ–≤–æ—Å—Ç–∏\n",
              "15    –Ω–∞–¥ –∞—Ä–º–µ–Ω–∏–µ–π –±—ã–ª —Å–±–∏—Ç –≤—Å–µ–≥–æ –æ–¥–∏–Ω —Ä–æ—Å—Å–∏–π—Å–∫–∏–π –≤–µ...\n",
              "16                         –≤ —ç—Ç–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ –≤—Å—ë\n",
              "17    –≤ –ø–µ—Ç–µ—Ä–±—É—Ä–≥–µ —Å—É–¥ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª –∏—Å–∫ –∂–µ–Ω—â–∏–Ω—ã –∫–æ—Ç–æ—Ä–∞...\n",
              "18               –±–∏–æ–≥—Ä–∞—Ñ–∏—è –æ–ª–µ–≥–∞ –º–µ–Ω—å—à–∏–∫–æ–≤–∞ —Ä–∏–∞ –Ω–æ–≤–æ—Å—Ç–∏\n",
              "19    –±–∏–æ–≥—Ä–∞—Ñ–∏—è –æ–ª–µ–≥–∞ –º–µ–Ω—å—à–∏–∫–æ–≤–∞—Ä–∏–∞ –Ω–æ–≤–æ—Å—Ç–∏–º–µ–Ω—å—à–∏–∫–æ–≤...\n",
              "20                        —É–º–µ—Ä —Ä–æ–º–∞–Ω –≤–∏–∫—Ç—é–∫ —Ä–∏–∞ –Ω–æ–≤–æ—Å—Ç–∏\n",
              "21    —É–º–µ—Ä —Ä–æ–º–∞–Ω –≤–∏–∫—Ç—é–∫—Ä–∏–∞ –Ω–æ–≤–æ—Å—Ç–∏—Ä–µ–∂–∏—Å—Å–µ—Ä —Ä–æ–º–∞–Ω –≤–∏–∫...\n",
              "22           —Ç—Ä–∞–º–ø–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥–∞–¥—É—Ç —Ä–∞–º–±–ª–µ—Ä–Ω–æ–≤–æ—Å—Ç–∏\n",
              "23    —Ç—Ä–∞–º–ø–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥–∞–¥—É—Ç—Ä–∞–º–±–ª–µ—Ä–Ω–æ–≤–æ—Å—Ç–∏—à—Ç–∞–± ...\n",
              "24                    –∞–∫—Ü–∏–∏ –æ –ø–æ–¥—Å–∫–æ—á–∏–ª–∏ —Ä–∞–º–±–ª–µ—Ä–Ω–æ–≤–æ—Å—Ç–∏\n",
              "25    –∞–∫—Ü–∏–∏ –æ –ø–æ–¥—Å–∫–æ—á–∏–ª–∏—Ä–∞–º–±–ª–µ—Ä–Ω–æ–≤–æ—Å—Ç–∏ –æ–±—ä—è–≤–∏–ª —Ü–µ–Ω—É ...\n",
              "26    –∑–µ–ª–µ–Ω—Å–∫–∏–π –±—É–¥–µ—Ç –µ–∂–µ–¥–Ω–µ–≤–Ω–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏...\n",
              "27    –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —É–∫—Ä–∞–∏–Ω—ã –≤–ª–∞–¥–∏–º–∏—Ä –∑–µ–ª–µ–Ω—Å–∫–∏–π –∑–∞—è–≤–∏–ª —á—Ç...\n",
              "28    –∞—Å–ø–∏—Ä–∏–Ω –ø—Ä–∏ –∫–æ—Ä–æ–Ω–∞–≤–∏—Ä—É—Å–µ –º–æ–∂–Ω–æ –∏–ª–∏ –Ω–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏...\n",
              "29    –∞—Å–ø–∏—Ä–∏–Ω –ø—Ä–∏ –∫–æ—Ä–æ–Ω–∞–≤–∏—Ä—É—Å–µ –º–æ–∂–Ω–æ –∏–ª–∏ –Ω–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏...\n",
              "30                                               —Ü–∏—Ç–∞—Ç–∞\n",
              "31    –º–∞–º–∞ —á–∏—Ç–∞—è –Ω–æ–≤–æ—Å—Ç–∏ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –∫–æ–Ω–µ—á–Ω–æ –∞—Ä–±–∞–ª–µ...\n",
              "32              –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –¥–∞–π–¥–∂–µ—Å—Ç —Å–æ–±—ã—Ç–∏–π –∏–∑ –º–∏—Ä–∞ –ø–ª–∏—Å\n",
              "33    –∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ –¥—Ä—É–∑—å—è –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª...\n",
              "34            –≤—ã–±–æ—Ä—ã–≤—ã–±–æ—Ä–∞–º–∏ –∞ –Ω–æ–≤–æ—Å—Ç–∏ –∏—Ç –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é\n",
              "35    –≤–∏–¥–µ–æ –Ω–∞ —Ñ–µ–π—Å–±—É–∫—Ç–µ–∫—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–¥ –∫–∞—Ç–æ–º–∏–∑ –±...\n",
              "36         –≤ –Ω—å—é–π–æ—Ä–∫–µ –Ω–∞—á–∞–ª–∏ –ø—Ä–∞–∑–¥–Ω–æ–≤–∞—Ç—å –ø–æ–±–µ–¥—É –±–∞–π–¥–µ–Ω–∞\n",
              "37    –≤ —Ü–µ–Ω—Ç—Ä–µ –Ω—å—é–π–æ—Ä–∫–∞ –∞–º–µ—Ä–∏–∫–∞–Ω—Ü—ã –Ω–∞—á–∞–ª–∏ –æ—Ç–º–µ—á–∞—Ç—å –ø...\n",
              "38    —Ç—É—Ä—Ü–∏—è –∑–∞—Ö–æ—Ç–µ–ª–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å —É —Å–µ–±—è —Ä–æ—Å—Å–∏–π—Å–∫—É—é ...\n",
              "39    —Ç—É—Ä—Ü–∏—è –∑–∞—Ö–æ—Ç–µ–ª–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å —É —Å–µ–±—è —Ä–æ—Å—Å–∏–π—Å–∫—É—é ...\n",
              "40                                               —Å—Ç–∞—Ç—å–∏\n",
              "41                                                     \n",
              "42    –≥–∞–Ω–≥—Å—Ç–µ—Ä—ã —Ä–∞—Å–∏–∑–º –∏ –Ω–∏—á–µ–≥–æ —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞–∫–∏–º –ø–æ–ª—É—á...\n",
              "43    –∑–∞—á–µ–º —Å—Ç–∞–ª–∏–Ω –∑–∞–≤–ª–∞–¥–µ–ª –ø—Ä–∏–±–∞–ª—Ç–∏–∫–æ–π –∏ —á—Ç–æ —Å –Ω–µ–π ...\n",
              "44    –ø–æ—á–µ–º—É –±–æ–≥–∞—Ç—ã–µ –ª—é–¥–∏ —Ç—Ä–∞—Ç—è—Ç —Ç—ã—Å—è—á–∏ –¥–æ–ª–ª–∞—Ä–æ–≤ –Ω–∞ ...\n",
              "45    –Ω–∞ –ª—é–±–∏–º–æ–º –∫—É—Ä–æ—Ä—Ç–µ —Ä–æ—Å—Å–∏—è–Ω –¥–µ—Ñ–∏—Ü–∏—Ç –∂–∏–ª—å—è –≥–¥–µ –≤...\n",
              "46    –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Ü—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è –≤ –∫–∞—Ä–∞–±–∞—Ö —Å–º–æ–≥—É—Ç –ª–∏...\n",
              "47     –æ—Ç–∫—Ä–æ–µ—Ç —Å–µ—Ç—å –∑–∞—Ä—è–¥–Ω—ã—Ö —Å—Ç–∞–Ω—Ü–∏–π –¥–ª—è —ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª–µ–π\n",
              "48    –∫–∞–∫ –ø—Ä–æ–µ–∫—Ç –∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω –ø–æ–º–æ–≥–∞–µ—Ç –∂–∏—Ç–µ–ª—è–º...\n",
              "49      –∫–∞–∫ –Ω–∞—á–∞—Ç—å –∏ —Ä–∞–∑–≤–∏—Ç—å —Å–≤–æ–µ –¥–µ–ª–æ —Å –ø–æ–º–æ—â—å—é –º–æ—Å–∫–≤—ã\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF7bR459dVrj",
        "outputId": "7664280e-d7a2-4370-aaa0-76acbab71980"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(total_words) \n",
        "input_sequences = []\n",
        "for line in data:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXxFxYAU4N08"
      },
      "source": [
        "max_sequence_length = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre'))"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z50RCt-vdeZ9"
      },
      "source": [
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcO6NpmwtMhr",
        "outputId": "c59423ff-0f4b-4b90-9f98-19600c2623ad"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 80, input_length=max_sequence_length-1))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(tf.keras.layers.Dropout(0.1))\n",
        "model.add(Dense(total_words/20))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 106, 80)           1292160   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 106, 100)          72400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 807)               41157     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16152)             13050816  \n",
            "=================================================================\n",
            "Total params: 14,486,733\n",
            "Trainable params: 14,486,733\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2pLKFUatMd1",
        "outputId": "59cc3a96-2299-495c-dcc5-04f448b6e2ab"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–±–µ–∫ —Å–æ—Ö—Ä–∞–Ω—è—é—â–∏–π –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å –Ω–æ–≤—ã–º –∫–æ–ª–ª–±–µ–∫–æ–º\n",
        "model.fit(train_images, \n",
        "          train_labels,  \n",
        "          epochs=10,\n",
        "          validation_data=(test_images,test_labels),\n",
        "          callbacks=[cp_callback])  # Pass callback to training\n",
        "\n",
        "# –≠—Ç–æ –º–æ–∂–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—é —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞.\n",
        "# –≠—Ç–∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (–∏ –ø–æ–¥–æ–±–Ω—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –≤ —ç—Ç–æ–º —É—Ä–æ–∫–µ)\n",
        "# –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Å—Ç–∞—Ä–µ–≤—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã.\n",
        "history = model.fit(xs, ys, epochs=200, verbose=1,callbacks=[cp_callback])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 1.9357 - accuracy: 0.6188\n",
            "Epoch 2/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 1.2370 - accuracy: 0.7112\n",
            "Epoch 3/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 1.0438 - accuracy: 0.7428\n",
            "Epoch 4/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.9671 - accuracy: 0.7609\n",
            "Epoch 5/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.9254 - accuracy: 0.7675\n",
            "Epoch 6/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.8793 - accuracy: 0.7809\n",
            "Epoch 7/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.8533 - accuracy: 0.7886\n",
            "Epoch 8/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.8079 - accuracy: 0.7973\n",
            "Epoch 9/100\n",
            "1569/1569 [==============================] - 39s 25ms/step - loss: 0.7827 - accuracy: 0.8026\n",
            "Epoch 10/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.7540 - accuracy: 0.8115\n",
            "Epoch 11/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.7451 - accuracy: 0.8116\n",
            "Epoch 12/100\n",
            "1569/1569 [==============================] - 39s 25ms/step - loss: 0.7306 - accuracy: 0.8148\n",
            "Epoch 13/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.7103 - accuracy: 0.8224\n",
            "Epoch 14/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.6875 - accuracy: 0.8265\n",
            "Epoch 15/100\n",
            "1569/1569 [==============================] - 39s 25ms/step - loss: 0.6640 - accuracy: 0.8304\n",
            "Epoch 16/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.6536 - accuracy: 0.8317\n",
            "Epoch 17/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.6601 - accuracy: 0.8302\n",
            "Epoch 18/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.6232 - accuracy: 0.8393\n",
            "Epoch 19/100\n",
            "1569/1569 [==============================] - 39s 25ms/step - loss: 0.6212 - accuracy: 0.8414\n",
            "Epoch 20/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.6098 - accuracy: 0.8422\n",
            "Epoch 21/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.5925 - accuracy: 0.8482\n",
            "Epoch 22/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.5847 - accuracy: 0.8508\n",
            "Epoch 23/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.5771 - accuracy: 0.8522\n",
            "Epoch 24/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.5651 - accuracy: 0.8550\n",
            "Epoch 25/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.5588 - accuracy: 0.8550\n",
            "Epoch 26/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.5408 - accuracy: 0.8602\n",
            "Epoch 27/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.5407 - accuracy: 0.8593\n",
            "Epoch 28/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.5362 - accuracy: 0.8631\n",
            "Epoch 29/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.5346 - accuracy: 0.8607\n",
            "Epoch 30/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.5272 - accuracy: 0.8631\n",
            "Epoch 31/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.5168 - accuracy: 0.8656\n",
            "Epoch 32/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4949 - accuracy: 0.8727\n",
            "Epoch 33/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4995 - accuracy: 0.8697\n",
            "Epoch 34/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.5037 - accuracy: 0.8678\n",
            "Epoch 35/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4897 - accuracy: 0.8729\n",
            "Epoch 36/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.4906 - accuracy: 0.8727\n",
            "Epoch 37/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.4806 - accuracy: 0.8744\n",
            "Epoch 38/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4749 - accuracy: 0.8759\n",
            "Epoch 39/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4648 - accuracy: 0.8770\n",
            "Epoch 40/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4694 - accuracy: 0.8757\n",
            "Epoch 41/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.4666 - accuracy: 0.8778\n",
            "Epoch 42/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4512 - accuracy: 0.8813\n",
            "Epoch 43/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.4593 - accuracy: 0.8795\n",
            "Epoch 44/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.4478 - accuracy: 0.8816\n",
            "Epoch 45/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4451 - accuracy: 0.8828\n",
            "Epoch 46/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4394 - accuracy: 0.8847\n",
            "Epoch 47/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4375 - accuracy: 0.8849\n",
            "Epoch 48/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4319 - accuracy: 0.8858\n",
            "Epoch 49/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4313 - accuracy: 0.8859\n",
            "Epoch 50/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4269 - accuracy: 0.8877\n",
            "Epoch 51/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4307 - accuracy: 0.8871\n",
            "Epoch 52/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.4314 - accuracy: 0.8851\n",
            "Epoch 53/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4100 - accuracy: 0.8909\n",
            "Epoch 54/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4110 - accuracy: 0.8902\n",
            "Epoch 55/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4091 - accuracy: 0.8929\n",
            "Epoch 56/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4057 - accuracy: 0.8922\n",
            "Epoch 57/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.4082 - accuracy: 0.8914\n",
            "Epoch 58/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4079 - accuracy: 0.8916\n",
            "Epoch 59/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3979 - accuracy: 0.8941\n",
            "Epoch 60/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3970 - accuracy: 0.8941\n",
            "Epoch 61/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4089 - accuracy: 0.8909\n",
            "Epoch 62/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.4026 - accuracy: 0.8916\n",
            "Epoch 63/100\n",
            "1569/1569 [==============================] - 40s 25ms/step - loss: 0.3946 - accuracy: 0.8959\n",
            "Epoch 64/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3987 - accuracy: 0.8951\n",
            "Epoch 65/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3917 - accuracy: 0.8962\n",
            "Epoch 66/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3866 - accuracy: 0.8965\n",
            "Epoch 67/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3868 - accuracy: 0.8970\n",
            "Epoch 68/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3762 - accuracy: 0.8982\n",
            "Epoch 69/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3820 - accuracy: 0.8990\n",
            "Epoch 70/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3728 - accuracy: 0.9007\n",
            "Epoch 71/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3730 - accuracy: 0.8997\n",
            "Epoch 72/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3766 - accuracy: 0.8980\n",
            "Epoch 73/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3735 - accuracy: 0.9018\n",
            "Epoch 74/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3665 - accuracy: 0.9013\n",
            "Epoch 75/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3686 - accuracy: 0.9005\n",
            "Epoch 76/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3683 - accuracy: 0.9009\n",
            "Epoch 77/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3626 - accuracy: 0.9014\n",
            "Epoch 78/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3617 - accuracy: 0.9014\n",
            "Epoch 79/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3651 - accuracy: 0.9028\n",
            "Epoch 80/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3576 - accuracy: 0.9036\n",
            "Epoch 81/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3635 - accuracy: 0.9018\n",
            "Epoch 82/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3578 - accuracy: 0.9033\n",
            "Epoch 83/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3555 - accuracy: 0.9061\n",
            "Epoch 84/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3518 - accuracy: 0.9059\n",
            "Epoch 85/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3542 - accuracy: 0.9042\n",
            "Epoch 86/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3560 - accuracy: 0.9039\n",
            "Epoch 87/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3473 - accuracy: 0.9060\n",
            "Epoch 88/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3516 - accuracy: 0.9054\n",
            "Epoch 89/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3486 - accuracy: 0.9065\n",
            "Epoch 90/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3447 - accuracy: 0.9063\n",
            "Epoch 91/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3421 - accuracy: 0.9083\n",
            "Epoch 92/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3457 - accuracy: 0.9061\n",
            "Epoch 93/100\n",
            "1569/1569 [==============================] - 40s 26ms/step - loss: 0.3441 - accuracy: 0.9072\n",
            "Epoch 94/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3367 - accuracy: 0.9085\n",
            "Epoch 95/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3411 - accuracy: 0.9073\n",
            "Epoch 96/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3353 - accuracy: 0.9093\n",
            "Epoch 97/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3411 - accuracy: 0.9081\n",
            "Epoch 98/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3397 - accuracy: 0.9086\n",
            "Epoch 99/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3386 - accuracy: 0.9088\n",
            "Epoch 100/100\n",
            "1569/1569 [==============================] - 41s 26ms/step - loss: 0.3371 - accuracy: 0.9094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n977WR1a9ISq"
      },
      "source": [
        "seed_text = \"—Ä–æ—Å—Å–∏—è\"\n",
        "next_words = 11"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cibyGXBwtNL4"
      },
      "source": [
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_length - 1, padding='pre')\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t6lwvS2k9XNi",
        "outputId": "62c0c354-4c85-4c00-f719-6b4c4f6dc3ae"
      },
      "source": [
        "seed_text"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'—Ä–æ—Å—Å–∏—è –æ—Ç–ø—Ä–∞–≤–∏—Ç –≤–∫–∞—Ä–∞–±–∞—Ö –ø–æ—á—Ç–∏ –¥–≤–µ —Ç—ã—Å—è—á–∏ –º–∏—Ä–æ—Ç–≤–æ—Ä—Ü–µ–≤ –ø–æ–∂–∏–ª—ã—Ö –ª—é–¥–µ–π –ø–æ –µ–µ —Å–ª–æ–≤–∞–º'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Agdg2nSOEX"
      },
      "source": [
        "/content/drive/MyDrive/Grocery2018_rus.pdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9qD-WlcSC8a"
      },
      "source": [
        "model.save('/content/drive/MyDrive/my_model.h5')"
      ],
      "execution_count": 149,
      "outputs": []
    }
  ]
}