{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMml0LB6wLMabqIOeSOFGIR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igorvojnyak/datavojnyak.github.io/blob/master/Text_Calssification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxG3xgVbg_TK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "161c84b6-28b3-44a0-a0aa-8cc7ea4b1901"
      },
      "source": [
        "pip install Flask\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6E4oZCehAo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "b736a3a7-3da9-4522-cd1d-7823775719a0"
      },
      "source": [
        "pip install Flask-RESTful"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Flask-RESTful\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/83/d0d33c971de2d38e54b0037136c8b8d20b9c83d308bc6c220a25162755fd/Flask_RESTful-0.3.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from Flask-RESTful) (2018.9)\n",
            "Collecting aniso8601>=0.82\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/e4/787e104b58eadc1a710738d4e418d7e599e4e778e52cb8e5d5ef6ddd5833/aniso8601-8.0.0-py2.py3-none-any.whl (43kB)\n",
            "\r\u001b[K     |███████▋                        | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 20kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 30kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 40kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from Flask-RESTful) (1.1.2)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from Flask-RESTful) (1.12.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->Flask-RESTful) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->Flask-RESTful) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->Flask-RESTful) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->Flask-RESTful) (2.11.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->Flask-RESTful) (1.1.1)\n",
            "Installing collected packages: aniso8601, Flask-RESTful\n",
            "Successfully installed Flask-RESTful-0.3.8 aniso8601-8.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOs4c2bWhBrE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e8f9abdf-8688-4756-9358-8412855ece3d"
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFvY8emBhETx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "734b0d7f-5b60-4e8d-e14a-8851a45fcd5e"
      },
      "source": [
        "pip install contractions"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 3.6MB/s \n",
            "\u001b[?25hCollecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 8.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81705 sha256=b5543845d35630f19b2ff4cab1f439485db22ae2c447ec62df9f8b65edecd2d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, Unidecode, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1VeiixDhG0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e558c89e-1380-4c5f-e920-dee937791956"
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gosKqtPhM0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8dc77f49-aacc-4813-b2ab-a7e2f3b991f7"
      },
      "source": [
        "pip install pyaspeller"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaspeller\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/78/0e9bc232c979c7f97ab6ac4d660d48546e69dd4897675bad125389465327/pyaspeller-0.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyaspeller) (1.12.0)\n",
            "Installing collected packages: pyaspeller\n",
            "Successfully installed pyaspeller-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aGs-Nqigwsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.externals import joblib\n",
        "import gensim\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULBie-3shO98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/Тестовое задание NLP - Training data.csv')\n",
        "test = pd.read_csv('/content/Тестовое задание NLP - Test data.csv')\n",
        "#df1 = pd.read_csv('/content/Тестовое задание NLP - Test data.csv')\n",
        "other_test = {'Пример текста': ['Кажется, ты сделал грубую ошибку.','Здесь очень быстро темнеет.','Говорят, зима будет холодной.','По-настоящему можно видеть только сердцем','Я прочитал письмо','Моя машина не заводится.','Ты пришел очень быстро']}\n",
        "other_train = {'Пример текста': ['Мне очень жаль','Прошу прощения','Простите не могу','Извините я хотел как лучше','Это очень мило с вашей стороны','В любом случае, спасибо','Спасибо заранее','Не стоит благодарности','Могу ли я вам помочь','Все в порядке','Не волнуйтесь об этом','Сюда пожалуйста']}\n",
        "data = pd.DataFrame(other_train)\n",
        "data['Класс']='other'\n",
        "train = pd.concat([train, data], ignore_index=True)\n",
        "data = pd.DataFrame(other_test)\n",
        "data['Класс']='other'\n",
        "test = pd.concat([test, data], ignore_index=True)\n",
        "train_text = train['Пример текста']\n",
        "test_text = test['Пример текста']\n",
        "all_text = pd.concat([train, test], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeocxCp7hO7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "speller = YandexSpeller(ignore_tags=True, ignore_digits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuOXOYFbhO4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=[w for w in test['Пример текста']]\n",
        "changes = {change['word']: change['s'][0] for change in speller.spell(text)}\n",
        "for word, suggestion in changes.items():\n",
        "    text = [ item.replace(word, suggestion) for item in text]\n",
        "test['Пример текста'] = pd.DataFrame(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbHAiO3yhO1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=[w for w in train['Пример текста']]\n",
        "changes = {change['word']: change['s'][0] for change in speller.spell(text)}\n",
        "for word, suggestion in changes.items():\n",
        "    text = [ item.replace(word, suggestion) for item in text]\n",
        "train['Пример текста'] = pd.DataFrame(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIUvRgH3hOyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "r =  re.compile(\"[а-яА-Я]+\")\n",
        "def preprocessing(line):\n",
        "    line = line.lower()\n",
        "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
        "    return line\n",
        "def remove_num(text):\n",
        "    return(''.join(ch for ch in text if not ch.isdigit()))\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^а-яА-Я+0-9\\s]' if not remove_digits else r'[^а-яА-Я+\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def tokenization_w(words):\n",
        "    w_new = []\n",
        "    for w in (words[:][0]):  # for NumPy = words[:]\n",
        "        w_token = word_tokenize(w)\n",
        "        if w_token != '':\n",
        "            w_new.append(w_token)\n",
        "    return w_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Saw6CVdshOvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.snowball import RussianStemmer\n",
        "stemmer = RussianStemmer(False)\n",
        "\n",
        "train['Пример текста'] = train['Пример текста'].apply(remove_special_characters)\n",
        "train['Пример текста']=train['Пример текста'].apply(lambda x: ''.join([stemmer.stem(word) for word in x]))\n",
        "train['Пример текста'] = [w for w in filter(r.match, train['Пример текста'])]\n",
        "train['Пример текста']= train['Пример текста'].apply(preprocessing)\n",
        "train = train.copy()\n",
        "train['Пример текста'] =train['Пример текста'].apply(lambda x: ' '.join([word for word in r.findall(x.lower())]))\n",
        "train['Пример текста'] =  train['Пример текста'].apply(lambda x:  ' '.join([contractions.fix(word) for word in x.split()]))\n",
        "train['Пример текста'] = train['Пример текста'].apply(remove_num)\n",
        "train['Пример текста'] =  train['Пример текста'].apply(lambda x: ''.join([word for word in x if word not in punctuation]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb35LYIghOs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['Пример текста'] = test['Пример текста'].apply(remove_special_characters)\n",
        "test['Пример текста']=test['Пример текста'].apply(lambda x: ''.join([stemmer.stem(word) for word in x]))\n",
        "test['Пример текста'] = [w for w in filter(r.match, test['Пример текста'])]\n",
        "test['Пример текста']= test['Пример текста'].apply(preprocessing)\n",
        "test = test.copy()\n",
        "test['Пример текста'] =test['Пример текста'].apply(lambda x: ' '.join([word for word in r.findall(x.lower())]))\n",
        "test['Пример текста'] =  test['Пример текста'].apply(lambda x:  ' '.join([contractions.fix(word) for word in x.split()]))\n",
        "test['Пример текста'] = test['Пример текста'].apply(remove_num)\n",
        "test['Пример текста'] =  test['Пример текста'].apply(lambda x: ''.join([word for word in x if word not in punctuation]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1ggNkLehOqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['Класс_id'] = train['Класс'].factorize()[0]\n",
        "category_id_df = train[['Пример текста', 'Класс_id']].drop_duplicates()\n",
        "test['Класс_id'] = test['Класс'].factorize()[0]\n",
        "category_id_df = test[['Пример текста', 'Класс_id']].drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X69uFhFMhOk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_8-_nh8hcm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train= train['Пример текста']\n",
        "test_X = test['Пример текста']\n",
        "y_train = train['Класс'] \n",
        "test_y = test['Класс']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_pF9h5fhfYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l1',alpha=1e-3, random_state=42, max_iter=5, tol=None)),])\n",
        "sgd.fit(X_train, y_train)\n",
        "y_pred = sgd.predict(test_X)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1G643R3hg2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(sgd, open('final_prediction.pickle', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js5aKWVth3ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca-NQjcPhh5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flask import Flask, request, redirect, url_for, flash, jsonify\n",
        "import numpy as np\n",
        "import pickle as p\n",
        "import json\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "\n",
        "@app.route('/api/', methods=['POST'])\n",
        "def makecalc():\n",
        "    data = request.get_json()\n",
        "    prediction = np.array2string(model.predict(data))\n",
        "\n",
        "    return jsonify(prediction)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    modelfile = '/content/final_prediction.pickle'\n",
        "    model = p.load(open(modelfile, 'rb'))\n",
        "    app.run(debug=True, host='0.0.0.0')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}