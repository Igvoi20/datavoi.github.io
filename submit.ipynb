{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "baseline.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiRVO0-TchOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "\n",
        "import catboost as cat\n",
        "from catboost import CatBoostClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP9YVz3IchOj",
        "colab_type": "code",
        "colab": {},
        "outputId": "27026a49-0eb9-427d-dc46-f1aa134cd40f"
      },
      "source": [
        "%%time\n",
        "edges = pd.read_csv('./edges.csv')\n",
        "ids = pd.read_csv('./ids.csv')\n",
        "vertices = pd.read_csv('./vertices.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.38 s, sys: 329 ms, total: 3.71 s\n",
            "Wall time: 3.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCLPUkFtchOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vertices['main_okved'] = vertices['main_okved'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYUc33H5chOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(7777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZohgLIUchOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pd.DataFrame(columns=['id_1', 'id_2'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1edLFjochOu",
        "colab_type": "code",
        "colab": {},
        "outputId": "170a01ff-87e8-44db-b184-fa4350b62834"
      },
      "source": [
        "# для каждой вершины из ids с помощью catboost найдем 1000 самых вероятных ребер\n",
        "for i in tqdm.tqdm(ids.id):\n",
        "    # соберем датасет из всех возможных вершин\n",
        "    # вершины имеющие в исходных данных ребро с i обозначим 1, остальные 0\n",
        "    # учтем то, что вершина i может быть как среди id_1, так и среди id_2\n",
        "    df1 = edges[edges['id_1'] == i].reset_index()\n",
        "    df2 = edges[edges['id_2'] == i].reset_index()\n",
        "\n",
        "    df = df1[['id_2', 'id_1']].rename(columns={'id_1':'id_2', 'id_2':'id_1'}).append(df2[['id_1', 'id_2']])\n",
        "    df['target'] = 1\n",
        "    \n",
        "    df = vertices.set_index('id').join(df.set_index('id_1')['target']).fillna(0)\n",
        "    \n",
        "    \n",
        "    X = df[['main_okved', 'region_code', 'company_type']]\n",
        "    y = df['target']\n",
        "    \n",
        "    \n",
        "    model = CatBoostClassifier(iterations=100, verbose=False)\n",
        "    cat_features = [0,1,2] # все признаки категориальные\n",
        "    \n",
        "    model.fit(X, y, cat_features)\n",
        "\n",
        "    preds = model.predict_proba(X)[:,1]\n",
        "\n",
        "    df['preds'] = preds\n",
        "    df['id_2'] = i\n",
        "    \n",
        "    # возьмем первую 1000 предсказанных ребер, исключив те, про которые мы уже знали\n",
        "    res = df[df['target'] != 1].sort_values(by='preds', ascending=False).iloc[:1000].reset_index()[['id', 'id_2']]\n",
        "    res.columns = ['id_1', 'id_2']\n",
        "    \n",
        "    result = result.append(res, ignore_index=True, sort=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [26:00<1:05:35, 54.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training has stopped (degenerate solution on iteration 93, probably too small l2-regularization, try to increase it)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [1:32:34<00:00, 54.28s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN7OPdSDj8V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X['n_common_neighbors'] = X.apply(lambda row:\n",
        "            len(tuple(nx.common_neighbors(g, row['node1'], row['node2']))), axis=1)\n",
        "pref_atts = nx.preferential_attachment(g, X[['node1', 'node2']].values)\n",
        "\n",
        "X['pref_att'] = [pref_att for u_, v_, pref_att in pref_atts]\n",
        "jacc_coefs = nx.jaccard_coefficient(g, X[['node1', 'node2']].values)\n",
        "\n",
        "X['jacc_coef'] = [jacc for u_, v_, jacc in jacc_coefs]\n",
        "adar_coefs = nx.adamic_adar_index(g, X[['node1', 'node2']].values)\n",
        "\n",
        "X['adar_coef'] = [adar for u_, v_, adar in adar_coefs]\n",
        "katz_dict = nx.katz_centrality(g, alpha=0.01)\n",
        "\n",
        "X['katz_sum'] = X.apply(lambda row: katz_dict[row['node1']] +\n",
        "                        katz_dict[row['node2']], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_fTsDjSdyaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)\n",
        "x_val=sc.transform(x_val)\n",
        "\n",
        "# Training\n",
        "d_train = lgb.Dataset(x_train, label=y_train)\n",
        "d_val = lgb.Dataset(x_val, label=y_val)\n",
        "d_test=lgb.Dataset(x_test,label=y_test)\n",
        "\n",
        "params = {\n",
        "            'objective': 'binary',\n",
        "            'boosting_type': 'gbdt',\n",
        "#             'boosting_type': 'rf',\n",
        "            'nthread': 4,\n",
        "            'learning_rate': 0.02,  # 02,\n",
        "            'num_leaves': 15,\n",
        "            'feature_fraction': 0.9,\n",
        "            'bagging_fraction': 0.7,\n",
        "            'bagging_freq': 1,\n",
        "            'early_stopping_round':5,\n",
        "            'max_depth':2,\n",
        "            'reg_alpha': 0.041545473,\n",
        "            'reg_lambda': 0.0735294,\n",
        "            'min_split_gain': 0.0222415,\n",
        "            'min_child_weight': 60,\n",
        "            'seed': 0,\n",
        "            'verbose': -1,\n",
        "            'metric': 'auc',\n",
        "}\n",
        "\n",
        "\n",
        "clf = lgb.train(params, d_train, 20,d_val)\n",
        "\n",
        "y_pred=clf.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy=accuracy_score(y_pred,y_test)\n",
        "print(accuracy)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8E4N070d3sF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testdata = pd.read_csv('test.csv')\n",
        "x_testing = testdata.iloc[:,0:FEATURE_SIZE].values\n",
        "x_testing = sc.transform(x_testing)\n",
        "y_pred=clf.predict(x_testing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1-ErJLad5iM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "with open(\"result.csv\",\"w\",newline=\"\") as csvfile:\n",
        "    writer=csv.writer(csvfile)\n",
        "    writer.writerow([\"Id\",\"Prediction\"])\n",
        "    test_id=1\n",
        "    for prediction in y_pred:\n",
        "        writer.writerow([test_id,prediction])\n",
        "        test_id+=1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}